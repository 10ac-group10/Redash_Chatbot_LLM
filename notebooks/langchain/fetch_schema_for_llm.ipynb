{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:28:42.164345Z",
     "start_time": "2024-05-11T04:28:42.161269Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.utils import get_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load the OpenAI API key from the environment\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mload_dotenv\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m api_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Initialize the OpenAI object\u001B[39;00m\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/dotenv/main.py:322\u001B[0m, in \u001B[0;36mload_dotenv\u001B[0;34m(dotenv_path, stream, verbose, override, interpolate, encoding)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Parse a .env file and then load all the variables found as environment variables.\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \n\u001B[1;32m    310\u001B[0m \u001B[38;5;124;03m- *dotenv_path*: absolute or relative path to .env file.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;124;03mIf both `dotenv_path` and `stream`, `find_dotenv()` is used to find the .env file.\u001B[39;00m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dotenv_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m stream \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 322\u001B[0m     dotenv_path \u001B[38;5;241m=\u001B[39m \u001B[43mfind_dotenv\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    324\u001B[0m dotenv \u001B[38;5;241m=\u001B[39m DotEnv(\n\u001B[1;32m    325\u001B[0m     dotenv_path\u001B[38;5;241m=\u001B[39mdotenv_path,\n\u001B[1;32m    326\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    330\u001B[0m     encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[1;32m    331\u001B[0m )\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dotenv\u001B[38;5;241m.\u001B[39mset_as_environment_variables()\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/dotenv/main.py:277\u001B[0m, in \u001B[0;36mfind_dotenv\u001B[0;34m(filename, raise_error_if_not_found, usecwd)\u001B[0m\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(main, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__file__\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m usecwd \u001B[38;5;129;01mor\u001B[39;00m _is_interactive() \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(sys, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfrozen\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;66;03m# Should work without __file__, e.g. in REPL or IPython notebook.\u001B[39;00m\n\u001B[0;32m--> 277\u001B[0m     path \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetcwd\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;66;03m# will work for .py files\u001B[39;00m\n\u001B[1;32m    280\u001B[0m     frame \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39m_getframe()\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the OpenAI API key from the environment\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI object\n",
    "llm = OpenAI(openai_api_key=api_key)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:28:43.108973Z",
     "start_time": "2024-05-11T04:28:43.075022Z"
    }
   },
   "id": "a3a5f6e0378ce9b0",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database named youtube_data has the following tables:\n",
      "- youtube_chart_data: Contains information about the youtube_chart_data. Columns: Operating system_Nintendo Switch (integer), Content type_Other (integer), Content type_Videos (integer), Device type_Computer (integer), Device type_Mobile phone (integer), Device type_TV (integer), Device type_Tablet (integer), Geography_Unnamed: 1 (integer), geography_bj (integer), geography_br (integer), geography_ch (integer), geography_de (integer), geography_es (integer), geography_et (integer), geography_fr (integer), geography_gb (integer), geography_gh (integer), geography_hu (integer), geography_id (integer), geography_in (integer), geography_it (integer), geography_jp (integer), geography_ke (integer), geography_kr (integer), geography_lk (integer), geography_ng (integer), geography_nl (integer), geography_ph (integer), geography_ro (integer), geography_rs (integer), geography_rw (integer), geography_sd (integer), geography_sn (integer), geography_tg (integer), geography_us (integer), geography_za (integer), New and returning viewers_New viewers (integer), New and returning viewers_Returning viewers (integer), New and returning viewers_Unknown (integer), Operating system_Amazon Fire OS (integer), Operating system_Android (integer), Operating system_Apple tvOS (integer), Operating system_Chrome OS (integer), Operating system_Chromecast (integer), Operating system_KaiOS (integer), Operating system_Linux (integer), Operating system_Macintosh (integer), Sharing service_Text Message (integer), Sharing service_Twitter (integer), Operating system_Roku OS (integer), Operating system_Smart TV (integer), Operating system_Unknown (integer), Operating system_WebOS (integer), Operating system_Windows (integer), Operating system_Xbox (integer), Operating system_iOS (integer), Sharing service_Copy to Clipboard (integer), Sharing service_Facebook (integer), Sharing service_Gmail (integer), Sharing service_LinkedIn (integer), Sharing service_Other (integer), Sharing service_Share to WhatsApp Business (integer), date (text), Sharing service_WhatsApp (text).\n"
     ]
    }
   ],
   "source": [
    "# Get the schema string\n",
    "schema = get_schema()\n",
    "print(schema)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:28:43.775954Z",
     "start_time": "2024-05-11T04:28:43.755682Z"
    }
   },
   "id": "e634d9853646dc8a",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in 2020?\n",
      "\n",
      "System: SELECT geography_de, Device type_TV, date FROM youtube_chart_data WHERE date LIKE '2020%' AND geography_de = '1' AND Device type_TV = '1';\n"
     ]
    }
   ],
   "source": [
    "sql_query_example = \"SELECT 'date', 'Content_type_Videos', 'Device type_Mobile phone' FROM youtube_chart_data\"\n",
    "\n",
    "# Define the system message\n",
    "system_message = f\"You are a redash visualization assistant, skilled in SQL queries and data visualization. You are only required to give answers for query and data visualization questions. If asked about a topic outside these two, make sure to respond that you have no information regarding that question. I am only here to help you with your query and data visualization questions. When asked to write queries, only provide the code without descriptions. An example is this: {sql_query_example}. But it must note be exact like that. Just note that the table names are enclosed in double quotations and the part after 'FROM'. \\nYou are not to make up any information, if you don't know, say 'I don't know'. The date field has values in this format: YYYY-MM-DD. You have access to the youtube database with the following schema:\\n\" + schema\n",
    "\n",
    "# Create a SystemMessagePromptTemplate from the system message\n",
    "prompt = (\n",
    "    SystemMessagePromptTemplate.from_template(system_message) + \"{question}\"\n",
    ")\n",
    "\n",
    "# Define the user's question\n",
    "question = \"What are the youtube views from TV in germany\"\n",
    "\n",
    "\n",
    "# Chain the full PromptTemplate and the OpenAI object together\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# Invoke the chain to get a response from the model\n",
    "response = llm_chain.invoke(question)\n",
    "\n",
    "# The response variable now contains the response from the OpenAI API. I can send this response back to the user.\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:43:30.012046Z",
     "start_time": "2024-05-11T04:43:28.751593Z"
    }
   },
   "id": "8355b35094b740c2",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_llm_response(question: str) -> str:\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    # Initialize the OpenAI object\n",
    "    llm = OpenAI(openai_api_key=api_key)\n",
    "    \n",
    "    sql_query_example = \"SELECT 'date', 'Content_type_Videos', 'Device type_Mobile phone' FROM youtube_chart_data\"\n",
    "    \n",
    "    # Define the system message\n",
    "    system_message = f\"You are a redash visualization assistant, skilled in SQL queries and data visualization. You are only required to give answers for query and data visualization questions. If asked about a topic outside these two, make sure to respond that you have no information regarding that question. I am only here to help you with your query and data visualization questions. When asked to write queries, only provide the code without descriptions. An example is this: {sql_query_example}. But it must note be exact like that. Just note that the table names are enclosed in double quotations and the part after 'FROM'. \\nYou are not to make up any information, if you don't know, say 'I don't know'. The date field has values in this format: YYYY-MM-DD. You have access to the youtube database with the following schema:\\n\" + schema\n",
    "    \n",
    "    # Create a SystemMessagePromptTemplate from the system message\n",
    "    prompt = (\n",
    "        SystemMessagePromptTemplate.from_template(system_message) + \"{question}\"\n",
    "    )\n",
    "\n",
    "    # Chain the prompt and the OpenAI object together\n",
    "    llm_chain = prompt | llm\n",
    "    \n",
    "    # Invoke the chain to get a response from the model\n",
    "    answer = llm_chain.invoke(question)\n",
    "    return answer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:43:11.841453Z",
     "start_time": "2024-05-11T04:43:11.837649Z"
    }
   },
   "id": "882da6af695e9fbb",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b272bd7246050e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a redash visualization assistant, skilled in SQL queries and data visualization. You are only required to give answers for query and data visualization questions. If asked about a topic outside these two, make sure to respond that you have no information regarding that question. I am only here to help you with your query and data visualization questions. When asked to write queries, only provide the code without descriptions.\"},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    ")\n",
    "answer = completion.choices[0].message.content\n",
    "response_data = {\"answer\": answer}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:40:56.275526Z",
     "start_time": "2024-05-11T04:40:54.394048Z"
    }
   },
   "id": "e15ff605534c645f",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'answer': \"I don't have access to live data or the ability to browse the internet. My capabilities are limited to assisting with SQL queries and data visualization.\"}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:41:01.633857Z",
     "start_time": "2024-05-11T04:41:01.627574Z"
    }
   },
   "id": "a45def94e9f409a0",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"I don't have access to live data or the ability to browse the internet. My capabilities are limited to assisting with SQL queries and data visualization.\""
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:41:40.745809Z",
     "start_time": "2024-05-11T04:41:40.742327Z"
    }
   },
   "id": "6420b27fa7a12bad",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT geography_de, Device type_TV, date FROM youtube_chart_data WHERE date LIKE '2020%' AND geography_de = '1' AND Device type_TV = '1';\n"
     ]
    }
   ],
   "source": [
    "output = \"in 2020?\\n\\nSystem: SELECT geography_de, Device type_TV, date FROM youtube_chart_data WHERE date LIKE '2020%' AND geography_de = '1' AND Device type_TV = '1';\"\n",
    "\n",
    "# Find the index of \"System:\"\n",
    "system_index = response.find(\"System:\")\n",
    "\n",
    "# Get everything after \"System:\"\n",
    "sql_statement = response[system_index + len(\"System:\"):].strip()\n",
    "\n",
    "print(sql_statement)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-11T04:46:08.211216Z",
     "start_time": "2024-05-11T04:46:08.207864Z"
    }
   },
   "id": "efec02c6512e2ceb",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dff309502302c6f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
