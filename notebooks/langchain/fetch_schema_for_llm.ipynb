{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-10T13:20:55.880017Z",
     "start_time": "2024-05-10T13:20:55.675531Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the OpenAI API key from the environment\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI object\n",
    "llm = OpenAI(openai_api_key=api_key)\n",
    "\n",
    "# Function to get the schema from the database\n",
    "def get_schema():\n",
    "    # Connect to your database\n",
    "    conn = psycopg2.connect(database=\"youtube_data\", user=\"postgres\", password=\"postgres\", host=\"localhost\", port=\"15432\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Query the information_schema to get the schema\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT table_name, column_name, data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'youtube_data_schema' AND table_name = 'youtube_info'\n",
    "    \"\"\")\n",
    "    # \n",
    "    # # Format the schema into a string\n",
    "    # schema = \"We have a database named youtube_data with the following tables:\\n\"\n",
    "    # for row in cur.fetchall():\n",
    "    #     schema += f\"- {row[0]}: Contains information about the {row[0]}. Columns: {row[1]} ({row[2]}).\\n\"\n",
    "    # Format the schema into a string\n",
    "    schema = \"The database named youtube_data has the following tables:\\n\"\n",
    "    \n",
    "    # Initialize an empty dictionary to store table information\n",
    "    tables = {}\n",
    "    \n",
    "    # Fetch all rows and organize them by table\n",
    "    for row in cur.fetchall():\n",
    "        table_name, column_name, data_type = row\n",
    "        if table_name not in tables:\n",
    "            tables[table_name] = []\n",
    "        tables[table_name].append(f\"{column_name} ({data_type})\")\n",
    "    \n",
    "    # Add table information to the schema string\n",
    "    for table_name, columns in tables.items():\n",
    "        schema += f\"- {table_name}: Contains information about the {table_name}. Columns: {', '.join(columns)}.\\n\"\n",
    "\n",
    "\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_data database has the following tables:\n",
      "- youtube_info: Contains information about the youtube_info. Columns: date (text), Content type_Other (integer), Content type_Videos (integer), Device type_Computer (integer), Device type_Mobile phone (integer), Device type_TV (integer), Device type_Tablet (integer), Geography_Unnamed: 1 (integer), geography_bj (integer), geography_br (integer), geography_ch (integer), geography_de (integer), geography_es (integer), geography_et (integer), geography_fr (integer), geography_gb (integer), geography_gh (integer), geography_hu (integer), geography_id (integer), geography_in (integer), geography_it (integer), geography_jp (integer), geography_ke (integer), geography_kr (integer), geography_lk (integer), geography_ng (integer), geography_nl (integer), geography_ph (integer), geography_ro (integer), geography_rs (integer), geography_rw (integer), geography_sd (integer), geography_sn (integer), geography_tg (integer), geography_us (integer), geography_za (integer), New and returning viewers_New viewers (integer), New and returning viewers_Returning viewers (integer), New and returning viewers_Unknown (integer), Operating system_Amazon Fire OS (integer), Operating system_Android (integer), Operating system_Apple tvOS (integer), Operating system_Chrome OS (integer), Operating system_Chromecast (integer), Operating system_KaiOS (integer), Operating system_Linux (integer), Operating system_Macintosh (integer), Operating system_Nintendo Switch (integer), Operating system_Roku OS (integer), Operating system_Smart TV (integer), Operating system_Unknown (integer), Operating system_WebOS (integer), Operating system_Windows (integer), Operating system_Xbox (integer), Operating system_iOS (integer), Sharing service_Copy to Clipboard (integer), Sharing service_Facebook (integer), Sharing service_Gmail (integer), Sharing service_LinkedIn (integer), Sharing service_Other (integer), Sharing service_Share to WhatsApp Business (integer), Sharing service_Text Message (integer), Sharing service_Twitter (integer), Sharing service_WhatsApp (text).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the schema string\n",
    "schema = get_schema()\n",
    "print(schema)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T13:20:57.476526Z",
     "start_time": "2024-05-10T13:20:57.450865Z"
    }
   },
   "id": "7654dcb8871a99c0",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptTemplate(input_variables=['question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a nice assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.fake import FakeStreamingListLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.runnables import Runnable\n",
    "from operator import itemgetter\n",
    "\n",
    "prompt = (\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a nice assistant.\")\n",
    "    + \"{question}\"\n",
    ")\n",
    "\n",
    "prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T13:28:20.149690Z",
     "start_time": "2024-05-10T13:28:20.143908Z"
    }
   },
   "id": "83515e1dfbccf9dc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "System: SELECT \"date\", \"Device type_TV\", \"geography_de\" FROM youtube_data_schema.youtube_info WHERE \"geography_de\" > 0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "sql_query_example = \"SELECT 'date', 'Content_type_Videos', 'Device type_Mobile phone' FROM youtube_data_schema.youtube_info WHERE 'geography_us' > 0\"\n",
    "\n",
    "# Define the system message\n",
    "system_message = f\"You are a nice assistant. You are trained to generate SQL queries for Redash based on user's questions. An example is this: {sql_query_example}. But it must note be exact like that. Just note that the table names are enclosed in double quotations and the part after 'FROM'. \\nYou are not to make up any information, if you don't know, say 'I don't know'. You have access to the youtube database with the following schema:\\n\" + schema\n",
    "\n",
    "# Create a SystemMessagePromptTemplate from the system message\n",
    "prompt = (\n",
    "    SystemMessagePromptTemplate.from_template(system_message) + \"{question}\"\n",
    ")\n",
    "\n",
    "# Define the user's question\n",
    "question = \"What are the youtube views from TV in germany\"\n",
    "\n",
    "\n",
    "# Chain the full PromptTemplate and the OpenAI object together\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# Invoke the chain to get a response from the model\n",
    "response = llm_chain.invoke(question)\n",
    "\n",
    "# The response variable now contains the response from the OpenAI API. I can send this response back to the user.\n",
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T14:25:49.197134Z",
     "start_time": "2024-05-10T14:25:47.699484Z"
    }
   },
   "id": "8355b35094b740c2",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected mapping type as input to PromptTemplate. Received <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Now you can use this chain to ask questions to the model\u001B[39;00m\n\u001B[1;32m      8\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat is the average price of the products ordered by user with id 1?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 9\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mllm_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# The response variable now contains the response from the OpenAI API. You can send this response back to the user.\u001B[39;00m\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config)\u001B[0m\n\u001B[1;32m   2497\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2498\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps):\n\u001B[0;32m-> 2499\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2500\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2501\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# mark each step as a child run\u001B[39;49;00m\n\u001B[1;32m   2502\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpatch_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2503\u001B[0m \u001B[43m                \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseq:step:\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2504\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2505\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2506\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   2507\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:128\u001B[0m, in \u001B[0;36mBasePromptTemplate.invoke\u001B[0;34m(self, input, config)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags:\n\u001B[1;32m    127\u001B[0m     config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags\n\u001B[0;32m--> 128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format_prompt_with_error_handling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1626\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1622\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1623\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(var_child_runnable_config\u001B[38;5;241m.\u001B[39mset, child_config)\n\u001B[1;32m   1624\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1625\u001B[0m         Output,\n\u001B[0;32m-> 1626\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1627\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1628\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1629\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1630\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1631\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1632\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1633\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1634\u001B[0m     )\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1636\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    346\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 347\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:111\u001B[0m, in \u001B[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_format_prompt_with_error_handling\u001B[39m(\u001B[38;5;28mself\u001B[39m, inner_input: Dict) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PromptValue:\n\u001B[0;32m--> 111\u001B[0m     _inner_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43minner_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_prompt(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_inner_input)\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:97\u001B[0m, in \u001B[0;36mBasePromptTemplate._validate_input\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m     94\u001B[0m         inner_input \u001B[38;5;241m=\u001B[39m {var_name: inner_input}\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     98\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected mapping type as input to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     99\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(inner_input)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    100\u001B[0m         )\n\u001B[1;32m    101\u001B[0m missing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_variables)\u001B[38;5;241m.\u001B[39mdifference(inner_input)\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing:\n",
      "\u001B[0;31mTypeError\u001B[0m: Expected mapping type as input to PromptTemplate. Received <class 'str'>."
     ]
    }
   ],
   "source": [
    "# Create a PromptTemplate from the schema\n",
    "schema_prompt = PromptTemplate.from_template(schema)\n",
    "\n",
    "# Chain the schema PromptTemplate and the OpenAI object together\n",
    "llm_chain = schema_prompt | llm\n",
    "\n",
    "# Now you can use this chain to ask questions to the model\n",
    "question = \"What is the average price of the products ordered by user with id 1?\"\n",
    "response = llm_chain.invoke(question)\n",
    "\n",
    "# The response variable now contains the response from the OpenAI API. You can send this response back to the user."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T13:17:26.648034Z",
     "start_time": "2024-05-10T13:17:25.713511Z"
    }
   },
   "id": "a272a5c6fd60081",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "882da6af695e9fbb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
