{
  "cells": [
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-18T15:43:22.547389Z",
          "start_time": "2024-05-18T15:43:21.319970Z"
        },
        "id": "4c3e5e022a0bac7a"
      },
      "id": "4c3e5e022a0bac7a",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "True"
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-18T15:43:22.558404Z",
          "start_time": "2024-05-18T15:43:22.549550Z"
        },
        "id": "9c21789728f4d7da",
        "outputId": "08bc2eac-00e6-42f6-c8a5-e58e65aee6d5"
      },
      "id": "9c21789728f4d7da",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-18T15:43:22.563972Z",
          "start_time": "2024-05-18T15:43:22.560346Z"
        },
        "id": "dcdc1493912b6085"
      },
      "id": "dcdc1493912b6085",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-18T15:43:22.569152Z",
          "start_time": "2024-05-18T15:43:22.566475Z"
        },
        "id": "1a3d398546df4a9e"
      },
      "id": "1a3d398546df4a9e",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "chatHistory = [{'name': 'geography_us', 'type': 'column', 'label': 'geography us'}, {'name': 'content_type_videos', 'type': 'column', 'label': 'content type videos'}]\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-18T15:43:22.575981Z",
          "start_time": "2024-05-18T15:43:22.571488Z"
        },
        "id": "67244aa5a93f0f51"
      },
      "id": "67244aa5a93f0f51",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "d1f80c4ea800052a"
      },
      "id": "d1f80c4ea800052a",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "def get_llm_response(question: str, chatHistory) -> str:\n",
        "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "    # Initialize the OpenAI object\n",
        "    llm = OpenAI(openai_api_key=api_key)\n",
        "\n",
        "    # Get the schema of the youtube_data database\n",
        "    # schema = get_schema()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # chatHistory = json.loads(chatHistory)\n",
        "    #\n",
        "    # # chat_history_string = \"\"\n",
        "    # # for item in chatHistory:\n",
        "    # #     chat_history_string += \"sender \" + item[\"sender\"] + \", text \" + item[\"text\"] + \"\\n\"\n",
        "    # #\n",
        "    # logging.info(type(chatHistory))\n",
        "    # logging.info(chatHistory)\n",
        "\n",
        "    sql_query_example = \"SELECT date, content_type_videos, device_type_mobile_phone FROM youtube_data_schema.youtube_chart_data\"\n",
        "\n",
        "    # Define the system message\n",
        "    system_message = (f\"You are a nice assistant. You are trained to generate SQL queries for Redash based on user's questions. \"\n",
        "                      f\"An example is this: {sql_query_example}. But the response could differ and may not be exactly like that. \"\n",
        "                      f\"Just note that the table names are enclosed in double quotations and the part after 'FROM' if we have the schema name. \\n\"\n",
        "                      f\"You are not to make up any information, if you don't know, say 'I don't know'. \"\n",
        "                      f\"Ensure you only provide a SQL query as a response without any punctutations, just plain SQL statement\"\n",
        "                      f\"The date field has values in this format: YYYY-MM-DD. \"\n",
        "                      f\"Avoid something like this: SQL Query: SELECT * FROM youtube_data_schema.youtube_chart_data.\"\n",
        "                      f\"Only start with SELECT statement without adding anything like 'SQL Query:'.\"\n",
        "                      f\"And DO NOT RETURN and query with punctuation marks irrelevant like ?\"\n",
        "                      f\"You will be given a schema with the table names and columns, do not deviate from the schema given and maintain the casing of the column names as provided in the schema.\"\n",
        "                      f\"Make sure you provide the correct SQL query with the correct format after FROM part like this: 'FROM youtube_data_schema.youtube_chart_data'.\"\n",
        "                      f\"Only give the first 10 results if the query is a SELECT statement for better visualizations. \\n\") + (f\"Here is your chart history: {chatHistory}\")\n",
        "\n",
        "    # Create a SystemMessagePromptTemplate from the system message\n",
        "    prompt = (\n",
        "        SystemMessagePromptTemplate.from_template(system_message) + \"{question}\"\n",
        "    )\n",
        "\n",
        "    # Chain the prompt and the OpenAI object together\n",
        "    llm_chain = prompt | llm\n",
        "\n",
        "    # Invoke the chain to get a response from the model\n",
        "    answer = llm_chain.invoke(question)\n",
        "    # answer = filter_llm_answer(answer)\n",
        "    return answer"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-18T15:43:30.749604Z",
          "start_time": "2024-05-18T15:43:30.745245Z"
        },
        "id": "f2f805e394b61ac0"
      },
      "id": "f2f805e394b61ac0",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat did you say before\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchatHistory\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[14], line 47\u001b[0m, in \u001b[0;36mget_llm_response\u001b[0;34m(question, chatHistory)\u001b[0m\n\u001b[1;32m     44\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Invoke the chain to get a response from the model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# answer = filter_llm_answer(answer)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
            "File \u001b[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:128\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    127\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1626\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1623\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1624\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1625\u001b[0m         Output,\n\u001b[0;32m-> 1626\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1634\u001b[0m     )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1636\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:111\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 111\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
            "File \u001b[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:97\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m     94\u001b[0m         inner_input \u001b[38;5;241m=\u001b[39m {var_name: inner_input}\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected mapping type as input to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(inner_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_variables)\u001b[38;5;241m.\u001b[39mdifference(inner_input)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>."
          ]
        }
      ],
      "source": [
        "get_llm_response(\"What did you say before\", chatHistory)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-18T15:43:32.092012Z",
          "start_time": "2024-05-18T15:43:31.462872Z"
        },
        "id": "3a8bcbe5747979ce",
        "outputId": "d49a23a7-5d8c-4f6d-965a-ea768b119fb5"
      },
      "id": "3a8bcbe5747979ce",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "3865381022cbd2a8"
      },
      "id": "3865381022cbd2a8",
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}