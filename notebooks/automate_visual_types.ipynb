{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T15:43:22.547389Z",
     "start_time": "2024-05-18T15:43:21.319970Z"
    }
   },
   "id": "4c3e5e022a0bac7a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T15:43:22.558404Z",
     "start_time": "2024-05-18T15:43:22.549550Z"
    }
   },
   "id": "9c21789728f4d7da",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T15:43:22.563972Z",
     "start_time": "2024-05-18T15:43:22.560346Z"
    }
   },
   "id": "dcdc1493912b6085",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T15:43:22.569152Z",
     "start_time": "2024-05-18T15:43:22.566475Z"
    }
   },
   "id": "1a3d398546df4a9e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chatHistory = [{'name': 'geography_us', 'type': 'column', 'label': 'geography us'}, {'name': 'content_type_videos', 'type': 'column', 'label': 'content type videos'}]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T15:43:22.575981Z",
     "start_time": "2024-05-18T15:43:22.571488Z"
    }
   },
   "id": "67244aa5a93f0f51",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d1f80c4ea800052a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_llm_response(question: str, chatHistory) -> str:\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "    # Initialize the OpenAI object\n",
    "    llm = OpenAI(openai_api_key=api_key)\n",
    "\n",
    "    # Get the schema of the youtube_data database\n",
    "    # schema = get_schema()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # chatHistory = json.loads(chatHistory)\n",
    "    #\n",
    "    # # chat_history_string = \"\"\n",
    "    # # for item in chatHistory:\n",
    "    # #     chat_history_string += \"sender \" + item[\"sender\"] + \", text \" + item[\"text\"] + \"\\n\"\n",
    "    # #\n",
    "    # logging.info(type(chatHistory))\n",
    "    # logging.info(chatHistory)\n",
    "\n",
    "    sql_query_example = \"SELECT date, content_type_videos, device_type_mobile_phone FROM youtube_data_schema.youtube_chart_data\"\n",
    "\n",
    "    # Define the system message\n",
    "    system_message = (f\"You are a nice assistant. You are trained to generate SQL queries for Redash based on user's questions. \"\n",
    "                      f\"An example is this: {sql_query_example}. But the response could differ and may not be exactly like that. \"\n",
    "                      f\"Just note that the table names are enclosed in double quotations and the part after 'FROM' if we have the schema name. \\n\"\n",
    "                      f\"You are not to make up any information, if you don't know, say 'I don't know'. \"\n",
    "                      f\"Ensure you only provide a SQL query as a response without any punctutations, just plain SQL statement\"\n",
    "                      f\"The date field has values in this format: YYYY-MM-DD. \"\n",
    "                      f\"Avoid something like this: SQL Query: SELECT * FROM youtube_data_schema.youtube_chart_data.\"\n",
    "                      f\"Only start with SELECT statement without adding anything like 'SQL Query:'.\"\n",
    "                      f\"And DO NOT RETURN and query with punctuation marks irrelevant like ?\"\n",
    "                      f\"You will be given a schema with the table names and columns, do not deviate from the schema given and maintain the casing of the column names as provided in the schema.\"\n",
    "                      f\"Make sure you provide the correct SQL query with the correct format after FROM part like this: 'FROM youtube_data_schema.youtube_chart_data'.\"\n",
    "                      f\"Only give the first 10 results if the query is a SELECT statement for better visualizations. \\n\") + (f\"Here is your chart history: {chatHistory}\")\n",
    "\n",
    "    # Create a SystemMessagePromptTemplate from the system message\n",
    "    prompt = (\n",
    "        SystemMessagePromptTemplate.from_template(system_message) + \"{question}\"\n",
    "    )\n",
    "\n",
    "    # Chain the prompt and the OpenAI object together\n",
    "    llm_chain = prompt | llm\n",
    "\n",
    "    # Invoke the chain to get a response from the model\n",
    "    answer = llm_chain.invoke(question)\n",
    "    # answer = filter_llm_answer(answer)\n",
    "    return answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T15:43:30.749604Z",
     "start_time": "2024-05-18T15:43:30.745245Z"
    }
   },
   "id": "f2f805e394b61ac0",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_llm_response\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhat did you say before\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchatHistory\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[14], line 47\u001B[0m, in \u001B[0;36mget_llm_response\u001B[0;34m(question, chatHistory)\u001B[0m\n\u001B[1;32m     44\u001B[0m llm_chain \u001B[38;5;241m=\u001B[39m prompt \u001B[38;5;241m|\u001B[39m llm\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# Invoke the chain to get a response from the model\u001B[39;00m\n\u001B[0;32m---> 47\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[43mllm_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# answer = filter_llm_answer(answer)\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m answer\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config)\u001B[0m\n\u001B[1;32m   2497\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2498\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps):\n\u001B[0;32m-> 2499\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2500\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2501\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# mark each step as a child run\u001B[39;49;00m\n\u001B[1;32m   2502\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpatch_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2503\u001B[0m \u001B[43m                \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseq:step:\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2504\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2505\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2506\u001B[0m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n\u001B[1;32m   2507\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:128\u001B[0m, in \u001B[0;36mBasePromptTemplate.invoke\u001B[0;34m(self, input, config)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags:\n\u001B[1;32m    127\u001B[0m     config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtags\n\u001B[0;32m--> 128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format_prompt_with_error_handling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrun_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1626\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1622\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1623\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(var_child_runnable_config\u001B[38;5;241m.\u001B[39mset, child_config)\n\u001B[1;32m   1624\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1625\u001B[0m         Output,\n\u001B[0;32m-> 1626\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1627\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1628\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1629\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1630\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1631\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1632\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1633\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1634\u001B[0m     )\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1636\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    346\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 347\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:111\u001B[0m, in \u001B[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_format_prompt_with_error_handling\u001B[39m(\u001B[38;5;28mself\u001B[39m, inner_input: Dict) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PromptValue:\n\u001B[0;32m--> 111\u001B[0m     _inner_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43minner_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_prompt(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_inner_input)\n",
      "File \u001B[0;32m~/code/10Academy-training/week3/redash_chatbot_LLM/.venv/lib/python3.10/site-packages/langchain_core/prompts/base.py:97\u001B[0m, in \u001B[0;36mBasePromptTemplate._validate_input\u001B[0;34m(self, inner_input)\u001B[0m\n\u001B[1;32m     94\u001B[0m         inner_input \u001B[38;5;241m=\u001B[39m {var_name: inner_input}\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     98\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected mapping type as input to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     99\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(inner_input)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    100\u001B[0m         )\n\u001B[1;32m    101\u001B[0m missing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_variables)\u001B[38;5;241m.\u001B[39mdifference(inner_input)\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing:\n",
      "\u001B[0;31mTypeError\u001B[0m: Expected mapping type as input to ChatPromptTemplate. Received <class 'str'>."
     ]
    }
   ],
   "source": [
    "get_llm_response(\"What did you say before\", chatHistory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T15:43:32.092012Z",
     "start_time": "2024-05-18T15:43:31.462872Z"
    }
   },
   "id": "3a8bcbe5747979ce",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3865381022cbd2a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
